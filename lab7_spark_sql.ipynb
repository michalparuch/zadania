{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnDVQJxX0PUjpMJZlYjX3t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michalparuch/PAD-zadania-/blob/main/lab7_spark_sql.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XidZPqPhCnGY"
      },
      "outputs": [],
      "source": [
        "  !apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "  !wget -q https://dlcdn.apache.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xf spark-3.3.1-bin-hadoop3.tgz"
      ],
      "metadata": {
        "id": "NC5b2dMCC780"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.1-bin-hadoop3\""
      ],
      "metadata": {
        "id": "HmwEGXFsC9QR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "zECqXidhC-bY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "BVtxLF1kDjRf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "findspark.find() # sprawdzenie gdzie znajduje siÄ™ instalka"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "snnBj6_8Dkkd",
        "outputId": "97003000-f529-4864-b757-7a6b125832c5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/spark-3.3.1-bin-hadoop3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1."
      ],
      "metadata": {
        "id": "DVa_T--zDtrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql import functions as func\n",
        "\n",
        "\n",
        "spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()\n",
        "\n",
        "\n",
        "def mapper(line):\n",
        "    fields = line.split(',')\n",
        "    return Row(Customer_ID=int(fields[0]), Item_ID=int(fields[1]), Order_value=float(fields[2]))\n",
        "    \n",
        "\n",
        "lines = spark.sparkContext.textFile(\"customer-orders.csv\")\n",
        "customers = lines.map(mapper)\n",
        "\n",
        "\n",
        "schemaCustomers = spark.createDataFrame(customers).cache()\n",
        "schemaCustomers.createOrReplaceTempView(\"customers\")\n",
        "schemaCustomers.groupBy(\"Customer_ID\").agg(func.round(func.sum('Order_value'),2)).show()\n",
        "\n",
        "\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGzJv8dNDtSe",
        "outputId": "b4f22767-d805-4ac5-8733-9ec2844957e2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------------------+\n",
            "|Customer_ID|round(sum(Order_value), 2)|\n",
            "+-----------+--------------------------+\n",
            "|         29|                   5032.53|\n",
            "|         26|                    5250.4|\n",
            "|         65|                   5140.35|\n",
            "|         54|                   6065.39|\n",
            "|         19|                   5059.43|\n",
            "|          0|                   5524.95|\n",
            "|         22|                   5019.45|\n",
            "|          7|                   4755.07|\n",
            "|         77|                   4327.73|\n",
            "|         34|                    5330.8|\n",
            "|         50|                   4517.27|\n",
            "|         94|                   4475.57|\n",
            "|         57|                    4628.4|\n",
            "|         43|                   5368.83|\n",
            "|         32|                   5496.05|\n",
            "|         84|                   4652.94|\n",
            "|         31|                   4765.05|\n",
            "|         98|                   4297.26|\n",
            "|         39|                   6193.11|\n",
            "|         25|                   5057.61|\n",
            "+-----------+--------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql import functions as func\n",
        "\n",
        "\n",
        "spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()\n",
        "\n",
        "\n",
        "def mapper(line):\n",
        "    fields = line.split(',')\n",
        "    return Row(Customer_ID=int(fields[0]), Item_ID=int(fields[1]), Order_value=float(fields[2]))\n",
        "    \n",
        "\n",
        "lines = spark.sparkContext.textFile(\"customer-orders.csv\")\n",
        "customers = lines.map(mapper)\n",
        "\n",
        "\n",
        "schemaCustomers = spark.createDataFrame(customers).cache()\n",
        "schemaCustomers.createOrReplaceTempView(\"customers\")\n",
        "schemaCustomers.groupBy(\"Customer_ID\").agg(func.round(func.sum('Order_value'),2).alias('Order_value_sorted')).orderBy('Order_value_sorted').show()\n",
        "\n",
        "\n",
        "\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ag5azjXrIJCz",
        "outputId": "49a29a86-c650-418b-9990-8e1e40e0b806"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------------+\n",
            "|Customer_ID|Order_value_sorted|\n",
            "+-----------+------------------+\n",
            "|         45|           3309.38|\n",
            "|         79|           3790.57|\n",
            "|         96|           3924.23|\n",
            "|         23|           4042.65|\n",
            "|         99|           4172.29|\n",
            "|         75|            4178.5|\n",
            "|         36|           4278.05|\n",
            "|         98|           4297.26|\n",
            "|         47|            4316.3|\n",
            "|         77|           4327.73|\n",
            "|         13|           4367.62|\n",
            "|         48|           4384.33|\n",
            "|         49|            4394.6|\n",
            "|         94|           4475.57|\n",
            "|         67|           4505.79|\n",
            "|         50|           4517.27|\n",
            "|         78|           4524.51|\n",
            "|          5|           4561.07|\n",
            "|         57|            4628.4|\n",
            "|         83|            4635.8|\n",
            "+-----------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}